{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "LSTM - Sentiment (SST2).ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_cDm4_9A5qN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#imports \n",
        "#from tensorflow import keras\n",
        "import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.layers import LSTM,Dense,Input,Bidirectional\n",
        "from nltk.tokenize.treebank import TreebankWordTokenizer\n",
        "from scipy import spatial\n",
        "from random import shuffle\n",
        "import pickle as pk\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from scipy import spatial\n",
        "import csv\n",
        "import requests\n",
        "import json\n",
        "from textblob import TextBlob\n",
        "from __future__ import print_function\n",
        "import os\n",
        "import sys\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Dense, Input, GlobalMaxPooling1D\n",
        "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
        "from keras.models import Model\n",
        "from keras.initializers import Constant\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90tNDjSwdjUb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install axel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jtiDG_7dvgp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!axel -n 30 http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOUNkGCFjDY5",
        "colab_type": "code",
        "outputId": "f05314b2-8885-4c3d-847e-3acb1046256b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "!apt-get install unzip\n",
        "!unzip glove.6B.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "unzip is already the newest version (6.0-21ubuntu1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-430\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded.\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwZ4nR_HeAGB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BASE_DIR = ''\n",
        "GLOVE_DIR = os.path.join(BASE_DIR, '')\n",
        "TEXT_DATA_DIR = os.path.join(BASE_DIR, '20_newsgroup')\n",
        "MAX_SEQUENCE_LENGTH = 50\n",
        "MAX_NUM_WORDS = 20000\n",
        "EMBEDDING_DIM = 300\n",
        "VALIDATION_SPLIT = 0.2\n",
        "batch_size = 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlXElkPMexkh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('https://github.com/clairett/pytorch-sentiment-classification/raw/master/data/SST2/train.tsv', delimiter='\\t', header=None)\n",
        "df = df[:3000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRJO-JaWi9ws",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embeddings_index = {}\n",
        "with open(os.path.join(GLOVE_DIR, 'glove.6B.300d.txt')) as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, 'f', sep=' ')\n",
        "        embeddings_index[word] = coefs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mke0fCquBWmU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texts = list(df[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8k7krmn94PZN",
        "colab_type": "code",
        "outputId": "51a1327b-8df4-4443-9c70-f057fe1a2469",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "print(texts[0])\n",
        "sequences = tokenizer.texts_to_sequences(texts)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a stirring , funny and finally transporting re imagining of beauty and the beast and 1930s horror films\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_25dORRRDHbF",
        "colab_type": "code",
        "outputId": "9e83f31e-7174-4276-ffcb-a62bbaa7c276",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 9046 unique tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxWW2krDDLIu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_len = 0\n",
        "for i in sequences:\n",
        "  if len(i) > max_len:\n",
        "    max_len = len(i)\n",
        "MAX_SEQUENCE_LENGTH = max_len"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qM0CM3Y6Ebr3",
        "colab_type": "code",
        "outputId": "f43c46ca-d582-4f32-ba22-89482b68ca49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxqapeUvF4y6",
        "colab_type": "code",
        "outputId": "b4058a0f-51e0-4c58-940b-79a34c7c5292",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "labels = np.array(df[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTMwRKwSKZoo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "data = data[indices]\n",
        "labels = labels[indices]\n",
        "num_validation_samples = int(VALIDATION_SPLIT * data.shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCdi7mHJM9s1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = data[:-num_validation_samples]\n",
        "y_train = labels[:-num_validation_samples]\n",
        "x_val = data[-num_validation_samples:]\n",
        "y_val = labels[-num_validation_samples:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1DoerzgM_nk",
        "colab_type": "code",
        "outputId": "e3c766c2-f847-4398-ab41-f1afb359a3d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "num_words = min(MAX_NUM_WORDS, len(word_index) + 1)\n",
        "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
        "for word, i in word_index.items():\n",
        "    if i >= MAX_NUM_WORDS:\n",
        "        continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "\n",
        "embedding_layer = Embedding(num_words,\n",
        "                            EMBEDDING_DIM,\n",
        "                            embeddings_initializer=Constant(embedding_matrix),\n",
        "                            input_length=MAX_SEQUENCE_LENGTH,\n",
        "                            trainable=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lizvO4sIZWkk",
        "colab_type": "code",
        "outputId": "b1096a88-ed64-407e-ab07-f3ede30104ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "embedding_layer"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.embeddings.Embedding at 0x7f3d18c4f550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eExKfTraYUDk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(embedding_layer)\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "model.add(Bidirectional(LSTM(64)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        " \n",
        "model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oztYNBQyZ6lb",
        "colab_type": "code",
        "outputId": "1cde74b9-291d-484a-9453-8b725362f1ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=4,\n",
        "          validation_data=[x_val, y_val])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2400 samples, validate on 600 samples\n",
            "Epoch 1/4\n",
            "2400/2400 [==============================] - 22s 9ms/step - loss: 0.2912 - acc: 0.8721 - val_loss: 0.4603 - val_acc: 0.7900\n",
            "Epoch 2/4\n",
            "2400/2400 [==============================] - 22s 9ms/step - loss: 0.2728 - acc: 0.8867 - val_loss: 0.5239 - val_acc: 0.8000\n",
            "Epoch 3/4\n",
            "2400/2400 [==============================] - 22s 9ms/step - loss: 0.2138 - acc: 0.9125 - val_loss: 0.6249 - val_acc: 0.7867\n",
            "Epoch 4/4\n",
            "2400/2400 [==============================] - 22s 9ms/step - loss: 0.1616 - acc: 0.9400 - val_loss: 0.6135 - val_acc: 0.7800\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3d1a396208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    }
  ]
}